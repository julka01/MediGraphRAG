#!/usr/bin/env python3
"""
Test KG generation using OpenRouter model to isolate the 502 error issue.
"""

import os
import sys
import json
from pathlib import Path

# Add the project root to Python path
ROOT_DIR = Path(__file__).parent.absolute()
sys.path.insert(0, str(ROOT_DIR))
sys.path.append(str(ROOT_DIR / 'llm-graph-builder/backend/src'))

from dotenv import load_dotenv
from ontology_guided_kg_creator import OntologyGuidedKGCreator
from model_providers import get_llm_provider

# Load environment variables
load_dotenv()

def test_openrouter_kg_generation():
    """Test KG generation using OpenRouter model"""

    print("üîß Testing OpenRouter KG Generation...")
    print("=" * 50)

    # Check API key
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    if not openrouter_key:
        print("‚ùå ERROR: OPENROUTER_API_KEY not found in environment")
        return False

    print(f"‚úÖ OpenRouter API Key found: {openrouter_key[:10]}...")

    # Get ontology path
    ontology_path = ROOT_DIR / "biomedical_ontology.owl"
    if not ontology_path.exists():
        print(f"‚ùå ERROR: Ontology file not found: {ontology_path}")
        return False

    print(f"‚úÖ Ontology file found: {ontology_path}")

    # Get test text
    test_file_path = ROOT_DIR / "prostate_cancer_guidelines.txt"
    if not test_file_path.exists():
        print(f"‚ùå ERROR: Test file not found: {test_file_path}")
        return False

    try:
        with open(test_file_path, 'r', encoding='utf-8') as f:
            test_text = f.read()

        print(f"‚úÖ Test file loaded: {len(test_text)} characters")

        # Test LLM provider loading first
        print("\nüîç Testing LLM provider setup...")
        try:
            # Manual configuration for OpenRouter
            model_config = "meta-llama/llama-4-maverick:free"
            llm_provider = get_llm_provider("openrouter", model_config)
            if llm_provider:
                print("‚úÖ OpenRouter LLM provider loaded successfully")
            else:
                print("‚ùå ERROR: Failed to load OpenRouter LLM provider")
                return False

        except Exception as e:
            print(f"‚ùå ERROR: LLM provider setup failed: {e}")
            print("This could be due to OpenRouter service issues or configuration problems")
            return False

        print("\nüöÄ Starting KG generation...")

        # Initialize KG creator
        kg_creator = OntologyGuidedKGCreator(
            chunk_size=1500,
            chunk_overlap=200,
            neo4j_uri=os.getenv('NEO4J_URI', 'bolt://localhost:7687'),
            neo4j_user=os.getenv('NEO4J_USERNAME', 'neo4j'),
            neo4j_password=os.getenv('NEO4J_PASSWORD', 'password'),
            neo4j_database=os.getenv('NEO4J_DATABASE', 'neo4j'),
            embedding_model="openai",
            ontology_path=str(ontology_path)
        )

        print(f"‚úÖ KG Creator initialized with ontology: {len(kg_creator.ontology_classes)} classes")

        # Generate the KG
        try:
            kg_result = kg_creator.generate_knowledge_graph(
                text=test_text,
                llm=llm_provider,
                file_name="OpenRouter-Test-KG",
                model_name=model_config
            )

            print("‚úÖ SUCCESS: KG generation completed!")
            print(f"   - Nodes: {kg_result.get('metadata', {}).get('total_entities', 0)}")
            print(f"   - Relationships: {kg_result.get('metadata', {}).get('total_relationships', 0)}")
            print(f"   - Chunks: {kg_result.get('metadata', {}).get('total_chunks', 0)}")

            return True

        except Exception as e:
            print(f"‚ùå ERROR during KG generation: {e}")
            print(f"   Error type: {type(e).__name__}")
            if "502" in str(e):
                print("   üí° This is a server connectivity issue with OpenRouter")
                print("   üí° Try switching to OpenAI model in the UI")
            elif "rate limit" in str(e).lower():
                print("   ‚ö° This is a rate limiting issue")
                print("   üí° Wait a few minutes and try again")
            elif "authentication" in str(e).lower():
                print("   üîê This is an API key authentication issue")
                print("   üí° Check OPENROUTER_API_KEY in .env file")
            return False

    except Exception as e:
        print(f"‚ùå ERROR during setup: {e}")
        return False

if __name__ == "__main__":
    print("üß™ OpenRouter KG Generation Test")
    print("=" * 50)

    success = test_openrouter_kg_generation()

    print("\n" + "=" * 50)
    if success:
        print("üéâ TEST PASSED: OpenRouter KG generation working!")
        print("‚úÖ The issue has been resolved - proceed with UI testing")
    else:
        print("‚ö†Ô∏è  TEST FAILED: OpenRouter KG generation issue detected")
        print("üí° Try switching to OpenAI model in the UI")
        print("      ./start_server.py && navigate to http://localhost:8000")
        print("      Select OpenAI from the KG provider dropdown")
        print("      Upload file and create KG")
