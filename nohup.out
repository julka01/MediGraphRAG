INFO:     Started server process [58749]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)
KGLoader initialized with Neo4j URI: bolt://localhost:7687
Loaded MODEL_PROVIDERS: [
  "openrouter",
  "lmu_lightllm",
  "ollama",
  "openai"
]
OpenRouter API key present: True
INFO:     127.0.0.1:59323 - "HEAD / HTTP/1.1" 405 Method Not Allowed
INFO:     127.0.0.1:59328 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:59328 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:59328 - "GET /models/openai HTTP/1.1" 200 OK
INFO:     127.0.0.1:59329 - "GET /models/openrouter HTTP/1.1" 200 OK
INFO:     127.0.0.1:59330 - "GET /models/openai HTTP/1.1" 200 OK
INFO:     127.0.0.1:59331 - "GET /models/openrouter HTTP/1.1" 200 OK
INFO:     127.0.0.1:59328 - "GET /list_stored_kgs HTTP/1.1" 200 OK
/Users/sahibjulka/Documents/work/tool-2025-kg-rag/app.py:699: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.
  vector_store.persist()
Creating vector store with provider: ollama
Embeddings object type: <class 'langchain_ollama.embeddings.OllamaEmbeddings'>
Loaded stored KG KG_ollama_deepseek_r1.json with ID: kg_5b3e3552-72b
INFO:     127.0.0.1:59329 - "POST /load_stored_kg HTTP/1.1" 200 OK
INFO:     127.0.0.1:59346 - "GET /models/ollama HTTP/1.1" 200 OK
INFO:     127.0.0.1:59347 - "GET /models/ollama HTTP/1.1" 200 OK
Error loading OWL ontology: 'http://www.semanticweb.org/ontologies/2018/1/ProstateCancer.owl#Occupation' belongs to more than one entity types (cannot be both a property and a class/an individual)!
Manually parsed OWL: 614 classes, 32 properties
Error generating KG: model 'llama3' not found (status code: 404)
Creating vector store with provider: ollama
Embeddings object type: <class 'langchain_ollama.embeddings.OllamaEmbeddings'>
KG stored successfully with ID: kg_c804b1d0-7e0
INFO:     127.0.0.1:59350 - "POST /load_kg_from_file HTTP/1.1" 200 OK
Chat request received - Question: 'describe the graph', KG ID: 'kg_c804b1d0-7e0'
Looking up KG context for ID: kg_c804b1d0-7e0
Retrieved 5 relevant context chunks from vector store
Using KG context for ID: kg_c804b1d0-7e0
INFO:     127.0.0.1:59944 - "POST /chat HTTP/1.1" 200 OK
INFO:     127.0.0.1:60612 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:60612 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:60612 - "GET /models/openai HTTP/1.1" 200 OK
INFO:     127.0.0.1:60613 - "GET /models/openrouter HTTP/1.1" 200 OK
INFO:     127.0.0.1:60614 - "GET /models/openai HTTP/1.1" 200 OK
INFO:     127.0.0.1:60615 - "GET /models/openrouter HTTP/1.1" 200 OK
INFO:     127.0.0.1:60612 - "GET /models/ollama HTTP/1.1" 200 OK
INFO:     127.0.0.1:60613 - "GET /models/ollama HTTP/1.1" 200 OK
INFO:     127.0.0.1:60620 - "GET /list_stored_kgs HTTP/1.1" 200 OK
Error loading OWL ontology: 'http://www.semanticweb.org/ontologies/2018/1/ProstateCancer.owl#Occupation' belongs to more than one entity types (cannot be both a property and a class/an individual)!
Manually parsed OWL: 614 classes, 32 properties
JSON parsing failed: Expecting value: line 14 column 3 (char 245)
Raw response: Based on the provided clinical text, I will extract relevant information and create a comprehensive knowledge graph. Please note that the extraction guidelines are followed carefully.

**Nodes:**

1. Prostate Cancer (Disease) - "Prostate cancer is a complex disease..."
	* Properties:
		+ name: Prostate Cancer
		+ stage: T2c
		+ evidence_level: 1a
		+ clinical_significance: High
		+ ontology_id: DOID:10283
2. Epidemiology and Risk Prevention (Guideline) - "Prostate cancer is the second most commo...
Error generating KG: Failed to parse JSON from model response
Creating vector store with provider: ollama
Embeddings object type: <class 'langchain_ollama.embeddings.OllamaEmbeddings'>
KG stored successfully with ID: kg_adcd95ce-401
INFO:     127.0.0.1:60629 - "POST /load_kg_from_file HTTP/1.1" 200 OK
INFO:     127.0.0.1:60685 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:60685 - "GET /models/openai HTTP/1.1" 200 OK
INFO:     127.0.0.1:60686 - "GET /models/openrouter HTTP/1.1" 200 OK
INFO:     127.0.0.1:60687 - "GET /models/openai HTTP/1.1" 200 OK
INFO:     127.0.0.1:60688 - "GET /models/openrouter HTTP/1.1" 200 OK
INFO:     127.0.0.1:60685 - "GET /models/ollama HTTP/1.1" 200 OK
INFO:     127.0.0.1:60686 - "GET /models/ollama HTTP/1.1" 200 OK
Error loading OWL ontology: 'http://www.semanticweb.org/ontologies/2018/1/ProstateCancer.owl#Occupation' belongs to more than one entity types (cannot be both a property and a class/an individual)!
Manually parsed OWL: 614 classes, 32 properties
Error generating KG: Error code: 429 - {'error': {'message': 'Provider returned error', 'code': 429, 'metadata': {'raw': 'deepseek/deepseek-r1-0528:free is temporarily rate-limited upstream. Please retry shortly, or add your own key to accumulate your rate limits: https://openrouter.ai/settings/integrations', 'provider_name': 'Chutes'}}, 'user_id': 'user_30oyr2y7T5fxt42dt6iIWW47EL7'}
Creating vector store with provider: ollama
Embeddings object type: <class 'langchain_ollama.embeddings.OllamaEmbeddings'>
KG stored successfully with ID: kg_8b0d483a-ee2
INFO:     127.0.0.1:60702 - "POST /load_kg_from_file HTTP/1.1" 200 OK
INFO:     127.0.0.1:61034 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:61034 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:61034 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:61034 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:61359 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:61359 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     Started server process [76694]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)
KGLoader initialized with Neo4j URI: bolt://localhost:7687
Loaded MODEL_PROVIDERS: [
  "openrouter",
  "lmu_lightllm",
  "openai"
]
OpenRouter API key present: True
Error checking Ollama models: name 'OllamaProvider' is not defined
INFO:     127.0.0.1:62073 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:62073 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:63005 - "GET / HTTP/1.1" 307 Temporary Redirect
INFO:     127.0.0.1:63005 - "GET /static/index.html HTTP/1.1" 200 OK
INFO:     127.0.0.1:63005 - "GET /providers HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:63005 - "GET /models/ HTTP/1.1" 404 Not Found
INFO:     127.0.0.1:63006 - "GET /models/ HTTP/1.1" 404 Not Found
INFO:     Started server process [83233]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)
INFO:     Started server process [83470]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)
INFO:     Started server process [83711]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
ERROR:    [Errno 48] error while attempting to bind on address ('0.0.0.0', 8004): address already in use
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
KGLoader initialized with Neo4j URI: bolt://localhost:7687
Loaded MODEL_PROVIDERS: [
  "openrouter",
  "lmu_lightllm",
  "ollama",
  "openai"
]
OpenRouter API key present: True
